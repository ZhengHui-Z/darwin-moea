# 常用工具接口：

模拟二进制交叉和多项式变异：

```python
from darwin.ea.operation.crossover.simulated_binary_crossover import SimulatedBinaryCrossover
from darwin.ea.operation.mutation.polynomial_mutation import PolynomialMutation

crossover = SimulatedBinaryCrossover(prob=1.0, eta=20)
mutation = PolynomialMutation(prob=1.0, eta=20)

# 调用和返回
crossover.do(bounds, genes)
mutation.do(bounds, genes)

# bounds参考测试问题
# 返回交叉和变异后的种群的决策变量
```

参考向量生成：

```pyhon
from darwin.ea.util.reference_direction import UniformReferenceDirection

`UniformReferenceDirection`方法：该方法作用是在空间内均匀的生成参考点，在`MOEAD`算法中用来生成参考向量。

传入参数：

- n_dim ：对应参考向量的维度
- n_points：需要生成多少个点，一般不回精确生成，只会生成接近数量的点，比如100通常会产生91个点
- n_partitions：每个维度划分几等分

返回参数：

- 对应数量的点的坐标
```

采样：

```python
from darwin.ea.operation.sampling import random_sampling

random_sampling中包含了如下两个方法

def float_random_sampling(bounds, n_samples, n_var):
    val = np.random.random((n_samples, n_var))
    return denormalize(val, bounds['xl'], bounds['xu'])


def binary_random_sampling(n_samples, n_var):
    val = np.random.random((n_samples, n_var))
    return (val < 0.5).astype(np.bool)
```

标准化：

```python
from darwin.ea.util import normalization

# normalization 中包含如下方法

def denormalize(x, x_min, x_max):
	# 生成某个区间内的浮点数
    if x_max is None:
        _range = 1
    else:
        _range = (x_max - x_min)

    return x * _range + x_min

def normalize(x, x_min=None, x_max=None, return_bounds=False, estimate_bounds_if_none=True):

    if estimate_bounds_if_none and x_min is None:
        x_min = np.min(x, axis=0)
    if estimate_bounds_if_none and x_max is None:
        x_max = np.max(x, axis=0)

    if x_min is None:
        x_min = np.zeros()
    if x_max is None:
        x_max = np.ones()

    denom = x_max - x_min

    # we can not divide by zero -> plus small epsilon
    denom += 1e-30

    # normalize the actual values
    N = (x - x_min) / denom

    # return with or without bounds
    if not return_bounds:
        return N
    else:
        return N, x_min, x_max


def standardize(x, return_bounds=False):
    mean = np.mean(x, axis=0)
    std = np.std(x, axis=0)

    # standardize
    val = (x - mean) / std

    if not return_bounds:
        return val
    else:
        return val, mean, std


def destandardize(x, mean, std):
    return (x * std) + mean
```

